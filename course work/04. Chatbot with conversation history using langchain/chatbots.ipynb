{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # loading all the environment variables\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "print(groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x10b2def50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x10b91d9d0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Navdeep, it's great to meet you! \\n\\nIt's awesome that you're learning about Generative AI. It's a really exciting field with a lot of potential. \\n\\nWhat specifically are you interested in learning about? \\n\\nFor example, are you curious about:\\n\\n* **Different types of generative models** (like text-to-image, text-to-code, etc.)?\\n* **How these models are trained?**\\n* **The ethical considerations surrounding Gen AI?**\\n* **Potential applications of Gen AI in different industries?**\\n\\nTell me more about your learning journey, and I'll do my best to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 21, 'total_tokens': 165, 'completion_time': 0.261818182, 'prompt_time': 0.000147949, 'queue_time': 0.015425541000000001, 'total_time': 0.261966131}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6478f126-3889-44a6-9348-7b5aff2926f8-0', usage_metadata={'input_tokens': 21, 'output_tokens': 144, 'total_tokens': 165})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi my name is Navdeep, I am learning Gen AI\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Navdeep, and you are learning about Generative AI! \\n\\nIs there anything else you'd like to tell me about yourself? üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 136, 'total_tokens': 176, 'completion_time': 0.072727273, 'prompt_time': 0.005244794, 'queue_time': 0.018165274999999998, 'total_time': 0.077972067}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a8c59a1f-a773-4ca6-b640-af6794cdce95-0', usage_metadata={'input_tokens': 136, 'output_tokens': 40, 'total_tokens': 176})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is Navdeep, I am learning Gen AI\"),\n",
    "        AIMessage(content=\"Hi Navdeep, it's great to meet you! It's awesome that you're learning \\\n",
    "                  about Generative AI. It's a really exciting field with a lot of potential. \\n\\nWhat \\\n",
    "                  specifically are you interested in learning about? \\n\\nFor example, are you curious about:\\n\\n* **\\\n",
    "                  Different types of generative models** (like text-to-image, text-to-code, etc.)?\\n* **\"),\n",
    "        HumanMessage(content=\"Hey, what's my name and what do i do ?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is Navdeep, I am learning Gen AI\")\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Navdeep! \\n\\nIt's great to meet you.  I'm glad to hear you're learning about Generative AI! It's a fascinating and rapidly developing field.  \\n\\nIs there anything in particular you'd like to know about Gen AI?  I can tell you about:\\n\\n* **What Gen AI is and how it works**\\n* **Different types of Gen AI models** (like me, text-based models, image generators, etc.)\\n* **Examples of what Gen AI can do** (write stories, compose music, create art, answer your questions!)\\n* **The ethical considerations surrounding Gen AI**\\n\\n\\nJust let me know where you'd like to start!  üòÑ  \\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Navdeep!  I remember that from our first conversation. üòä  \\n\\nIs there anything else I can help you with today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 409, 'total_tokens': 441, 'completion_time': 0.058181818, 'prompt_time': 0.014562931, 'queue_time': 0.0018160880000000022, 'total_time': 0.072744749}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-59839a77-9977-4324-b639-0cba4755f3f8-0', usage_metadata={'input_tokens': 409, 'output_tokens': 32, 'total_tokens': 441})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What's my name\")\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and don't know your name. If you'd like to tell me, I'm happy to know! üòä\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the config(session id)\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat_2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What's my name\")\n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John! It's nice to meet you.  \\n\\nIs there anything I can help you with today?  \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"My name is John\")\n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is John.  \\n\\nIt seems like you're repeating your name. Is there something specific you want to know about it, or are you just testing me? üòÑ  \\n\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What's my name\")\n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt templates\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Hey you are a helpful assistant. Answer the questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Navdeep\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Navdeep, it's nice to meet you! \\n\\nI'm ready to answer your questions to the best of my ability. What can I help you with today? üòä \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 32, 'total_tokens': 74, 'completion_time': 0.076363636, 'prompt_time': 0.000588559, 'queue_time': 0.013013031, 'total_time': 0.076952195}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-46e7e653-02b8-4484-8c67-371b9a3bb030-0', usage_metadata={'input_tokens': 32, 'output_tokens': 42, 'total_tokens': 74})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Navdeep, it's nice to meet you!  \\n\\nWhat can I do for you today? I'm ready for your questions üòä \\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat_3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hi my name is Navdeep\")]\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a helpful assistant. Answer all your the questions in best of your ability in {language}:\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§®‡§µ‡§¶‡•Ä‡§™! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§Æ‡•á‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡§®‡§æ ‡§ö‡§æ‡§π‡§æ‡•§  \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•Å‡§õ ‡§≠‡•Ä ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Ç‡§ó‡§æ‡•§  üòä \\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"My name is Navdeep\")],\n",
    "    \"language\":\"hindi\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now wrap this more complicated chain in a message history class.\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§®‡§µ‡§¶‡•Ä‡§™!  ‡§Æ‡•Å‡§ù‡•á ‡§ñ‡§º‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§®‡•á ‡§ï‡•ã ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat_4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hi I am Navdeep\")],\n",
    "        \"language\":\"hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Navdeep ‡§π‡•à‡•§  \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"What's my name?\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# managing the conversation history\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial = False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked:  \"What is 2 + 2?\" \\n\\nI answered: 4  üòä \\n\\n\\nLet me know if you have any other math problems or questions!\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What math proble i asked for ?\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets wrap this in message history\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history, \n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\":{\"session_id\":\"chat_5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me \"whats 2 + 2\".  üòä \\n\\n\\nLet me know if you have any other questions!\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What was the last math problem i asked ?\")],\n",
    "        \"language\":\"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
